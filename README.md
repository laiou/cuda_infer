---
infer_model
---
----------
&ensp;&ensp;This repo is use cpu or gpu to inference yolo-v3-tiny model,and the main test environment is:
***

    Ubuntu 18.04 LTS
    GPU 2080Ti
    CUDA 10.2
*** 
&ensp;&ensp;This case provide yolo-v3-tiny model inference option  with cpu and gpu,also can import others extension.And use this repo to inference please read the corresponding documentation in gpu or cpu file.
&ensp;&ensp;Or use "sudo ./inference -cpu ./test.jpg" to use cpu inference.


